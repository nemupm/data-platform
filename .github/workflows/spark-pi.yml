name: Update Spark Pi

on:
  push:
    branches: [ master ]
    paths:
      - 'spark/spark-pi/**'
  pull_request:
    branches: [ master ]
    paths:
      - 'spark/spark-pi/**'

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Set up JDK 1.8
        uses: actions/setup-java@v1
        with:
          java-version: 1.8

      - name: Build package
        run: sbt package
        working-directory: ./spark/spark-pi

      - name: Configure AWS credentials to s3 share bucket
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_S3_SHARE }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_S3_SHARE }}
          aws-region: ap-northeast-1

      - name: Upload file to S3
        env:
          S3_UPLOAD_BUCKET: share.nemupm.com
        run: |
          aws s3 cp ./spark-pi-project_2.12-1.0.jar s3://${S3_UPLOAD_BUCKET}/spark-application/ --quiet
        working-directory: ./spark/spark-pi
